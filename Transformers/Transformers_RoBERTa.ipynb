{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Transformers_RoBERTa.ipynb","provenance":[{"file_id":"1WjAGqEwwOS6zkdYK2IZc8udoWicn25Zx","timestamp":1627565917182},{"file_id":"1XF9F9_DSvPTf2s6NO1wKz9P9-sSE2CyI","timestamp":1627549915804},{"file_id":"1cPowJe9mhm7lP4d3UKC1SYJ-wEWBrHlV","timestamp":1627538690876}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"63315c79700b49cdb20f0c7c0b4c7476":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3266c25e525d42e2a0f31a2d2ce0e628","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3acfa965356349d6b272f99d2eea9161","IPY_MODEL_9c5cb77bfa9b4f98b256669b548f041c","IPY_MODEL_fb239d8512914c6fa4491e7a7470eeb8"]}},"3266c25e525d42e2a0f31a2d2ce0e628":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3acfa965356349d6b272f99d2eea9161":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_576b14bb32f04e779039db45df073b2d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b62494fe18a4415c8b5a6fdc04d3b364"}},"9c5cb77bfa9b4f98b256669b548f041c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_98a1f7c79c2242e397440b516ed1ef1d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":375,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":375,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a337c7b94a434f35b57d649049e63602"}},"fb239d8512914c6fa4491e7a7470eeb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_22022bbe5e37444d9f40ee7fe993b45b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 375/375 [02:51&lt;00:00,  2.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7169351fad44365865c22a1ccc05c6d"}},"576b14bb32f04e779039db45df073b2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b62494fe18a4415c8b5a6fdc04d3b364":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98a1f7c79c2242e397440b516ed1ef1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a337c7b94a434f35b57d649049e63602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22022bbe5e37444d9f40ee7fe993b45b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f7169351fad44365865c22a1ccc05c6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8BV3ODrkkxa2","executionInfo":{"status":"ok","timestamp":1627565967106,"user_tz":-480,"elapsed":13029,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"32311760-4aea-496a-dbac-d0451df1b3ce"},"source":["!pip install transformers\n","!pip install datasets"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 11.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 48.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 53.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 55.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n","Collecting datasets\n","  Downloading datasets-1.10.2-py3-none-any.whl (542 kB)\n","\u001b[K     |████████████████████████████████| 542 kB 11.6 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 27.6 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Collecting tqdm>=4.42\n","  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Collecting fsspec>=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 51.4 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: tqdm, xxhash, fsspec, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed datasets-1.10.2 fsspec-2021.7.0 tqdm-4.61.2 xxhash-2.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rUL7CBRAk0Xd","executionInfo":{"status":"ok","timestamp":1627565988118,"user_tz":-480,"elapsed":19073,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"b1b2a165-9ce4-47c7-f034-e9445ef073b2"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"egzB8750lgP_","executionInfo":{"status":"ok","timestamp":1627570807335,"user_tz":-480,"elapsed":2,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}}},"source":["root_dir = \"gdrive/MyDrive/Capstone/\"\n","\n","pretrained = \"roberta-base\"\n","model_checkpoint = pretrained\n","tokenizer_checkpoint = pretrained\n","\n","num_labels = 10\n","batch_size = 8"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"h75X6_wMk9b8","executionInfo":{"status":"ok","timestamp":1627570823215,"user_tz":-480,"elapsed":4293,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}}},"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from transformers import AdamW, get_scheduler\n","\n","import torch\n","from torch.utils.data import DataLoader\n","\n","from datasets import load_dataset, load_metric, load_from_disk\n","\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n","\n","import pickle\n","from tqdm.auto import tqdm"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"glMocgCVlRJj","executionInfo":{"status":"ok","timestamp":1627570823864,"user_tz":-480,"elapsed":653,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"1f221dda-e9e3-4b23-f34a-f6c4b72481eb"},"source":["dataset = load_dataset('csv', data_files=root_dir + 'df_cleaned.csv', split='train')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using custom data configuration default-863e501dda6703d2\n","Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-863e501dda6703d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Lu0rnt3lXDh","executionInfo":{"status":"ok","timestamp":1627570827445,"user_tz":-480,"elapsed":3582,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"1eb1f4df-7bf1-4c5c-c0f5-eeeceb76ed4c"},"source":["tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"tweet_text_cleaned\"], padding=\"max_length\", truncation=True)\n","\n","tokenized_datasets = dataset.train_test_split(test_size=0.1).map(tokenize_function, batched=True)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Loading cached split indices for dataset at /root/.cache/huggingface/datasets/csv/default-863e501dda6703d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-16cc27aa8ace637b.arrow and /root/.cache/huggingface/datasets/csv/default-863e501dda6703d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-9287c69e8d270862.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-863e501dda6703d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-0c9f25bc547d5809.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-863e501dda6703d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-5487cef7100ff762.arrow\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zrjOKKoPlb8Y","executionInfo":{"status":"ok","timestamp":1627570827445,"user_tz":-480,"elapsed":7,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}}},"source":["tokenized_datasets = tokenized_datasets.remove_columns(['class_label', \n","                                                        'data_type', \n","                                                        'event',\n","                                                        'event_type',\n","                                                        'file_name',\n","                                                        'hashtags',\n","                                                        'processed_text_length',\n","                                                        #'token_type_ids',\n","                                                        'tweet_id',\n","                                                        'tweet_text',\n","                                                        'tweet_text_cleaned',\n","                                                        'year'])\n","tokenized_datasets = tokenized_datasets.rename_column(\"class_label_id\", \"labels\")\n","tokenized_datasets.set_format(\"torch\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"yyMyoop5pEQr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627570827446,"user_tz":-480,"elapsed":7,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"c00c2e50-3cb8-4de6-bb5d-6948cee63611"},"source":["small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n","small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n","\n","train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=batch_size)\n","eval_dataloader = DataLoader(small_eval_dataset, batch_size=batch_size)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-863e501dda6703d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-bccbae190d62effe.arrow\n","Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-863e501dda6703d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-a70efc740d4f809d.arrow\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ApiGf0ZpIzF","executionInfo":{"status":"ok","timestamp":1627570833324,"user_tz":-480,"elapsed":5883,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"0fd3bed8-7c04-4adb-f7cd-64d796bfa644"},"source":["model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKnxH7GhdS-1","executionInfo":{"status":"ok","timestamp":1627570833325,"user_tz":-480,"elapsed":10,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"b0dc904d-044c-43fd-b2f5-4b70cbb7f543"},"source":["device"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"6FjhVCC7pSF7","executionInfo":{"status":"ok","timestamp":1627570833326,"user_tz":-480,"elapsed":6,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}}},"source":["optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","num_epochs = 3\n","num_training_steps = num_epochs * len(train_dataloader)\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["63315c79700b49cdb20f0c7c0b4c7476","3266c25e525d42e2a0f31a2d2ce0e628","3acfa965356349d6b272f99d2eea9161","9c5cb77bfa9b4f98b256669b548f041c","fb239d8512914c6fa4491e7a7470eeb8","576b14bb32f04e779039db45df073b2d","b62494fe18a4415c8b5a6fdc04d3b364","98a1f7c79c2242e397440b516ed1ef1d","a337c7b94a434f35b57d649049e63602","22022bbe5e37444d9f40ee7fe993b45b","f7169351fad44365865c22a1ccc05c6d"]},"id":"cdhiCGqWpZMM","executionInfo":{"status":"ok","timestamp":1627571004239,"user_tz":-480,"elapsed":170919,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"2f00118d-1051-4d5b-a7e5-2c0c5004432a"},"source":["progress_bar = tqdm(range(num_training_steps))\n","\n","model.train()\n","for epoch in range(num_epochs):\n","    for batch in train_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = model(**batch)\n","        loss = outputs.loss\n","        loss.backward()\n","\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.update(1)"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63315c79700b49cdb20f0c7c0b4c7476","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/375 [00:00<?, ?it/s]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kfPBE1tEpbkj","executionInfo":{"status":"ok","timestamp":1627571024336,"user_tz":-480,"elapsed":20106,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"1de7b5ef-c0b7-4e46-983d-e60f85da8076"},"source":["metric= load_metric(\"accuracy\")\n","model.eval()\n","for batch in eval_dataloader:\n","    batch = {k: v.to(device) for k, v in batch.items()}\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","\n","    logits = outputs.logits\n","    predictions = torch.argmax(logits, dim=-1)\n","    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","\n","metric.compute()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 0.715}"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"v3BpjLav1VAa","executionInfo":{"status":"ok","timestamp":1627571024337,"user_tz":-480,"elapsed":9,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}}},"source":["metric_name = \"accuracy\"\n","\n","args = TrainingArguments(\n","    \"capstone_\"+pretrained,\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    metric_for_best_model=metric_name,\n",")"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"rmPOuYm43unA","executionInfo":{"status":"ok","timestamp":1627571024887,"user_tz":-480,"elapsed":558,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}}},"source":["metric= load_metric(\"accuracy\")\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=1)\n","    return metric.compute(predictions=predictions, references=labels)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"EUHq9gD13-QK","executionInfo":{"status":"ok","timestamp":1627571024888,"user_tz":-480,"elapsed":4,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}}},"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ujcllY8c4JNK","executionInfo":{"status":"ok","timestamp":1627583925107,"user_tz":-480,"elapsed":12900223,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"7090346a-cf8d-4052-8ff9-107ca8441ca0"},"source":["trainer.train()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["***** Running training *****\n","  Num examples = 68834\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 25815\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='25815' max='25815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [25815/25815 3:34:59, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.686500</td>\n","      <td>0.707856</td>\n","      <td>0.754478</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.577400</td>\n","      <td>0.664842</td>\n","      <td>0.771866</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.474600</td>\n","      <td>0.726794</td>\n","      <td>0.768205</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving model checkpoint to capstone_roberta-base/checkpoint-500\n","Configuration saved in capstone_roberta-base/checkpoint-500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-1000\n","Configuration saved in capstone_roberta-base/checkpoint-1000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-1000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-1500\n","Configuration saved in capstone_roberta-base/checkpoint-1500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-1500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-2000\n","Configuration saved in capstone_roberta-base/checkpoint-2000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-2000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-2500\n","Configuration saved in capstone_roberta-base/checkpoint-2500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-2500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-3000\n","Configuration saved in capstone_roberta-base/checkpoint-3000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-3000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-3500\n","Configuration saved in capstone_roberta-base/checkpoint-3500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-3500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-4000\n","Configuration saved in capstone_roberta-base/checkpoint-4000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-4000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-4500\n","Configuration saved in capstone_roberta-base/checkpoint-4500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-4500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-5000\n","Configuration saved in capstone_roberta-base/checkpoint-5000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-5000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-5500\n","Configuration saved in capstone_roberta-base/checkpoint-5500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-5500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-6000\n","Configuration saved in capstone_roberta-base/checkpoint-6000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-6000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-6500\n","Configuration saved in capstone_roberta-base/checkpoint-6500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-6500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-7000\n","Configuration saved in capstone_roberta-base/checkpoint-7000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-7000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-7500\n","Configuration saved in capstone_roberta-base/checkpoint-7500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-7500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-8000\n","Configuration saved in capstone_roberta-base/checkpoint-8000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-8000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-8500\n","Configuration saved in capstone_roberta-base/checkpoint-8500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-8500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 7649\n","  Batch size = 8\n","Saving model checkpoint to capstone_roberta-base/checkpoint-9000\n","Configuration saved in capstone_roberta-base/checkpoint-9000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-9000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-9500\n","Configuration saved in capstone_roberta-base/checkpoint-9500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-9500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-10000\n","Configuration saved in capstone_roberta-base/checkpoint-10000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-10000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-10500\n","Configuration saved in capstone_roberta-base/checkpoint-10500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-10500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-11000\n","Configuration saved in capstone_roberta-base/checkpoint-11000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-11000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-11500\n","Configuration saved in capstone_roberta-base/checkpoint-11500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-11500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-12000\n","Configuration saved in capstone_roberta-base/checkpoint-12000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-12000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-12500\n","Configuration saved in capstone_roberta-base/checkpoint-12500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-12500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-13000\n","Configuration saved in capstone_roberta-base/checkpoint-13000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-13000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-13500\n","Configuration saved in capstone_roberta-base/checkpoint-13500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-13500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-14000\n","Configuration saved in capstone_roberta-base/checkpoint-14000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-14000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-14500\n","Configuration saved in capstone_roberta-base/checkpoint-14500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-14500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-15000\n","Configuration saved in capstone_roberta-base/checkpoint-15000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-15000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-15500\n","Configuration saved in capstone_roberta-base/checkpoint-15500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-15500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-16000\n","Configuration saved in capstone_roberta-base/checkpoint-16000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-16000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-16000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-16500\n","Configuration saved in capstone_roberta-base/checkpoint-16500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-16500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-16500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-17000\n","Configuration saved in capstone_roberta-base/checkpoint-17000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-17000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-17000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 7649\n","  Batch size = 8\n","Saving model checkpoint to capstone_roberta-base/checkpoint-17500\n","Configuration saved in capstone_roberta-base/checkpoint-17500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-17500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-17500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-18000\n","Configuration saved in capstone_roberta-base/checkpoint-18000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-18000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-18000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-18000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-18500\n","Configuration saved in capstone_roberta-base/checkpoint-18500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-18500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-18500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-18500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-19000\n","Configuration saved in capstone_roberta-base/checkpoint-19000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-19000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-19000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-19000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-19500\n","Configuration saved in capstone_roberta-base/checkpoint-19500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-19500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-19500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-19500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-20000\n","Configuration saved in capstone_roberta-base/checkpoint-20000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-20000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-20000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-20000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-20500\n","Configuration saved in capstone_roberta-base/checkpoint-20500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-20500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-20500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-20500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-21000\n","Configuration saved in capstone_roberta-base/checkpoint-21000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-21000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-21000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-21000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-21500\n","Configuration saved in capstone_roberta-base/checkpoint-21500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-21500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-21500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-21500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-22000\n","Configuration saved in capstone_roberta-base/checkpoint-22000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-22000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-22000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-22000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-22500\n","Configuration saved in capstone_roberta-base/checkpoint-22500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-22500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-22500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-22500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-23000\n","Configuration saved in capstone_roberta-base/checkpoint-23000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-23000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-23000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-23000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-23500\n","Configuration saved in capstone_roberta-base/checkpoint-23500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-23500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-23500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-23500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-24000\n","Configuration saved in capstone_roberta-base/checkpoint-24000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-24000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-24000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-24000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-24500\n","Configuration saved in capstone_roberta-base/checkpoint-24500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-24500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-24500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-24500/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-25000\n","Configuration saved in capstone_roberta-base/checkpoint-25000/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-25000/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-25000/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-25000/special_tokens_map.json\n","Saving model checkpoint to capstone_roberta-base/checkpoint-25500\n","Configuration saved in capstone_roberta-base/checkpoint-25500/config.json\n","Model weights saved in capstone_roberta-base/checkpoint-25500/pytorch_model.bin\n","tokenizer config file saved in capstone_roberta-base/checkpoint-25500/tokenizer_config.json\n","Special tokens file saved in capstone_roberta-base/checkpoint-25500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 7649\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=25815, training_loss=0.595012334823239, metrics={'train_runtime': 12899.9065, 'train_samples_per_second': 16.008, 'train_steps_per_second': 2.001, 'total_flos': 5.433686182368461e+16, 'train_loss': 0.595012334823239, 'epoch': 3.0})"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213},"id":"ciI44DKX4Kfq","executionInfo":{"status":"ok","timestamp":1627584075145,"user_tz":-480,"elapsed":64529,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"edbbd05e-61ac-403e-bec2-fac1e4dde25e"},"source":["trainer.evaluate()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 7649\n","  Batch size = 8\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='543' max='957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [543/957 01:25 < 01:04, 6.37 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='957' max='957' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [957/957 02:30]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.768204994116878,\n"," 'eval_loss': 0.7267939448356628,\n"," 'eval_runtime': 150.3837,\n"," 'eval_samples_per_second': 50.863,\n"," 'eval_steps_per_second': 6.364}"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5MSIboOCvHx","executionInfo":{"status":"ok","timestamp":1627584078247,"user_tz":-480,"elapsed":3103,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"5ce1805b-6291-4ea3-dd63-52a9214ec763"},"source":["model.save_pretrained(root_dir + 'models/' + pretrained)\n","tokenizer.save_pretrained(root_dir + 'tokenizers/' + pretrained)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Configuration saved in gdrive/MyDrive/Capstone/models/roberta-base/config.json\n","Model weights saved in gdrive/MyDrive/Capstone/models/roberta-base/pytorch_model.bin\n","tokenizer config file saved in gdrive/MyDrive/Capstone/tokenizers/roberta-base/tokenizer_config.json\n","Special tokens file saved in gdrive/MyDrive/Capstone/tokenizers/roberta-base/special_tokens_map.json\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["('gdrive/MyDrive/Capstone/tokenizers/roberta-base/tokenizer_config.json',\n"," 'gdrive/MyDrive/Capstone/tokenizers/roberta-base/special_tokens_map.json',\n"," 'gdrive/MyDrive/Capstone/tokenizers/roberta-base/vocab.json',\n"," 'gdrive/MyDrive/Capstone/tokenizers/roberta-base/merges.txt',\n"," 'gdrive/MyDrive/Capstone/tokenizers/roberta-base/added_tokens.json',\n"," 'gdrive/MyDrive/Capstone/tokenizers/roberta-base/tokenizer.json')"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"ikNBcsQ8OPld","executionInfo":{"status":"ok","timestamp":1627584080343,"user_tz":-480,"elapsed":2097,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}}},"source":["tokenized_datasets.save_to_disk(root_dir + 'assets/datasets/' + pretrained)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vsR2kMxJd7yK"},"source":["# Results Visualization"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QY6cKE1NeE6f","executionInfo":{"status":"ok","timestamp":1627584080906,"user_tz":-480,"elapsed":561,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"7fdcd94b-09fb-438f-c9a1-51aa5581517a"},"source":["dataset = load_dataset('csv', data_files=root_dir + 'df_cleaned.csv', split='train')\n","tokenized_datasets = load_from_disk(root_dir + 'assets/datasets/' + pretrained)\n","tokenized_datasets.set_format(\"torch\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Using custom data configuration default-863e501dda6703d2\n","Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-863e501dda6703d2/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZOBGLq8fZjL","executionInfo":{"status":"ok","timestamp":1627584083041,"user_tz":-480,"elapsed":2137,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"6447c7c2-d4b8-400d-de83-9f2ed08fd916"},"source":["model_checkpoint = root_dir + \"models/\" + pretrained\n","tokenizer_checkpoint = root_dir + \"tokenizers/\" + pretrained\n","\n","model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=10)\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["loading configuration file gdrive/MyDrive/Capstone/models/roberta-base/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file gdrive/MyDrive/Capstone/models/roberta-base/pytorch_model.bin\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at gdrive/MyDrive/Capstone/models/roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4yDVNPRLiRc5","executionInfo":{"status":"ok","timestamp":1627584083041,"user_tz":-480,"elapsed":3,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"8d4fb464-20bd-41cc-c768-6d7749f614c9"},"source":["device"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aURRzMlvQAOr","executionInfo":{"status":"ok","timestamp":1627584229877,"user_tz":-480,"elapsed":146836,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}},"outputId":"7bf2b1c7-c47f-4e91-fb49-4c676dc1e018"},"source":["metric = load_metric(\"accuracy\")\n","eval_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=batch_size)\n","\n","model.eval()\n","#prob = []\n","y_pred = []\n","total_loss = 0.0\n","for batch in eval_dataloader:\n","    batch = {k: v.to(device) for k, v in batch.items()}\n","    with torch.no_grad():\n","        outputs = model(**batch)\n","\n","    total_loss += outputs.loss.item()\n","    logits = outputs.logits\n","    predictions = torch.argmax(logits, dim=-1)\n","    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","    #prob.extend(torch.nn.Softmax(dim=1)(outputs.logits))\n","    y_pred.extend([t.item() for t in predictions])\n","\n","loss = total_loss/tokenized_datasets[\"test\"].shape[0]\n","metric.compute()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 0.768204994116878}"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"1b_4ALSkQsYi"},"source":["y_true = tokenized_datasets[\"test\"][\"labels\"].numpy().tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lL8_9NzJSO-w"},"source":["assert len(y_true) == len(y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DGDrQ1WfILbI"},"source":["def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, path='cm', cmap=plt.cm.Reds):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","#     pickle.dump(cm, open(path, 'wb'))\n","\n","    fig, ax = plt.subplots(figsize=(15,15))\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    ax.figure.colorbar(im, ax=ax)\n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           # ... and label them with the respective list entries\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","\n","    # Loop over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    fig.tight_layout()\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LkWuLpJILh2"},"source":["label_name = sorted(pd.Series(dataset['class_label']).unique())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EhBSZM9BILlu"},"source":["accuracy = accuracy_score(y_true, y_pred)\n","matthews = matthews_corrcoef(y_true, y_pred)\n","\n","precisions = {}\n","recalls = {}\n","f1s = {}\n","aucrocs = {}\n","\n","for i in range(len(label_name)):\n","    prediction_ = [1 if pred == i else 0 for pred in y_pred]\n","    true_ = [1 if label == i else 0 for label in y_true]\n","    f1s.update({label_name[i]: f1_score(true_, prediction_)})\n","    precisions.update({label_name[i]: precision_score(true_, prediction_)})\n","    recalls.update({label_name[i]: recall_score(true_, prediction_)})\n","    # aucrocs.update({label_name[i]: roc_auc_score(true_, list(t.item() for t in prob[:, i]))})\n","\n","metrics_dict = {'loss': loss, 'accuracy': accuracy, 'matthews coef': matthews, 'precision': precisions,\n","                     'recall': recalls, 'f1': f1s, \n","                # 'aucroc': aucrocs\n","                }\n","\n","pickle.dump(metrics_dict, open(root_dir+'/output/evaluation_metrics/'+pretrained, 'wb'))\n","\n","cm = plot_confusion_matrix(y_true, y_pred, label_name, normalize=False,\n","                      path='test_confusion_matrix', title='confusion matrix for test dataset')\n","plt.savefig(root_dir+'/output/confusion_matrix/'+pretrained, format='png')\n","cm_norm = plot_confusion_matrix(y_true, y_pred, label_name, normalize=True,\n","                      path='test normalized_confusion_matrix', title='normalized confusion matrix for test dataset')\n","plt.savefig(root_dir+'/output/normalized_confusion_matrix/'+pretrained, format='png')\n","\n","print('loss: %.2f' % loss)\n","print('accuracy: %.2f' % accuracy)\n","print('matthews coef: %.2f' % matthews)\n","for i in range(len(label_name)):\n","    print('precision score for %s: %.2f' % (label_name[i], precisions[label_name[i]]))\n","    print('recall score for %s: %.2f' % (label_name[i], recalls[label_name[i]]))\n","    print('f1 score for %s: %.2f' % (label_name[i], f1s[label_name[i]]))\n","    # print('auc roc score for %s: %.2f' % (label_name[i], aucrocs[label_name[i]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HdAIUFHAILor","executionInfo":{"status":"ok","timestamp":1627584234935,"user_tz":-480,"elapsed":1,"user":{"displayName":"Lin Di","photoUrl":"","userId":"02321472830486637167"}}},"source":["with open(root_dir+'/output/evaluation_metrics/'+pretrained, 'rb') as file:\n","    p = pickle.load(file)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"0e4gExPjb5qu"},"source":[""],"execution_count":null,"outputs":[]}]}